{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbrazonath/CEIA_Analisis_de_datos/blob/main/CNN_implementacion_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wIQ8hjDpdVi"
      },
      "source": [
        "## Importar lo necesario y establecemos la configuracines necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uHQUjDs12DLW",
        "outputId": "60f8a24a-7eb1-4ef9-e138-f528baf9caea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2866522069.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;31m# pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;31m# para cargar datasets y transformaciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;31m# para generar numeros aleatorios y probar nuestro modelo entrenado (buscando aleatoriamente ejemplos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m \u001b[0;31m# para graficar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;31m# para graficar la barra de avance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgiou_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneralized_box_iou_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSqueezeExcitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compile_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackTrigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         GroebnerBasis, poly)\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m from .polyfuncs import (symmetrize, horner, interpolate,\n\u001b[0m\u001b[1;32m     80\u001b[0m         rational_interpolate, viete)\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/polyfuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyoptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoly_from_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from sympy.polys.specialpolys import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     symmetric_poly, interpolating_poly)\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/specialpolys.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;31m# A few useful polynomials from Wang's paper ('78).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_f_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/rings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m from sympy.polys.polyutils import (expr_from_dict, _dict_reorder,\n\u001b[1;32m     29\u001b[0m                                    _parallel_dict_from_expr)\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultPrinting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/printing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_ccode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/printing/pycode.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodePrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m _kw = {\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/printing/codeprinter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_sort_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrPrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRECEDENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/functions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0merfinv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merfcinv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merf2inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         fresnels, fresnelc)\n\u001b[0;32m---> 31\u001b[0;31m from sympy.functions.special.gamma_functions import (gamma, lowergamma,\n\u001b[0m\u001b[1;32m     32\u001b[0m         uppergamma, polygamma, loggamma, digamma, trigamma, multigamma)\n\u001b[1;32m     33\u001b[0m from sympy.functions.special.zeta_functions import (dirichlet_eta, zeta,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/functions/special/gamma_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRational\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeta_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0merf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpolarify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch # pytorch\n",
        "import torchvision # para cargar datasets y transformaciones\n",
        "import random # para generar numeros aleatorios y probar nuestro modelo entrenado (buscando aleatoriamente ejemplos)\n",
        "import matplotlib.pyplot as plt # para graficar\n",
        "from tqdm import tqdm # para graficar la barra de avance\n",
        "import wandb # hacer log en wheights and bias\n",
        "from torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingWarmRestarts # modificar LR conforme se entrena"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biK7BQSsgEM0",
        "outputId": "54de8ae4-831f-457c-bd9b-7c8ba1cbabc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "# instalar torchinfo para ver el modelo y sus parametros\n",
        "!pip install torchinfo\n",
        "import torchinfo as torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJy8fjPn4wi"
      },
      "source": [
        "### configuramos el `device` acorde al device disponible\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lOV9xybtn4I3",
        "outputId": "e255d0ae-c42c-4a1c-9fca-8ea003bbf075"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IROzIJYLho4P"
      },
      "source": [
        "### nos vinculamos al weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjEyZuHV97Iw",
        "outputId": "0653dda2-2c8c-4a50-938b-1226010bd1c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlelectronfou\u001b[0m (\u001b[33mmmaillot\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# key de Marcos Uriel Maillot (lelectronfou@gmail.com), cámbiela a su usario una vez finalizada la clase.\n",
        "wandb.login(key=\"d63a15806a812590a5525d000eed0e6d6c57a023\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_tH9u082jpZ"
      },
      "source": [
        "\n",
        "\n",
        "## Ejemplo de red neuronal de convolución (CNN)\n",
        "**MNIST data base**\n",
        "Vamos a usar la base de datos de MNIST ([ver fuente](http://yann.lecun.com/exdb/mnist/)) para entrenar una CNN que identifique números escritos a mano.\n",
        "\n",
        "Para esto necesitamos:\n",
        "\n",
        "\n",
        "1.   Cargar la base de datos.\n",
        "2.   Ver que la base de datos esté ok.\n",
        "3.   Construir nuestra CNN.\n",
        "4. Ver que las dimensiones de la red sean consistentes.\n",
        "4.   Definir funciones necesarias (de entrenamiento, de costo, etc.).\n",
        "5. Entrenar la red.\n",
        "6. Ver que funcione.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nQ-MLk6Do8e"
      },
      "source": [
        "## 1. Cargar base de datos\n",
        "\n",
        "De la documentación, ver:\n",
        "\n",
        "\n",
        "Transformación `torchvision.transforms.ToTensor()`\n",
        "\n",
        "```\n",
        "... Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]...\n",
        "```\n",
        "\n",
        "Transformación `Normalize`\n",
        "\n",
        "```\n",
        "... Normalize a tensor image with mean and standard deviation. ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JvzatGF4e0W",
        "outputId": "d20f9777-a74d-4134-fe3b-b0507f82cbb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 4.96MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.60MB/s]\n"
          ]
        }
      ],
      "source": [
        "# definimos un conjunto de transformaciones para el dataset MNIST\n",
        "# (pasamos de imagenes de 28x28 a tensores, normalizamos, etc.)\n",
        "tranformaciones = torchvision.transforms.Compose([\n",
        "                            torchvision.transforms.ToTensor(),#<---------------- escala entre 0 y 1; pasa a tensor; poner canal en 1ra dim\n",
        "                            torchvision.transforms.Normalize((0.1307,), (0.3081,))#<----------------- normaliza el dataset; media y desviación estándar de los datos\n",
        "                            ])\n",
        "\n",
        "\n",
        "# creamos el dataset (para cargar los datos a procesar) MNIST de entrenamiento y test\n",
        "# (descargamos los datos si no están en la carpeta ../data)\n",
        "train_dataset = torchvision.datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=tranformaciones\n",
        "                      )\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST('../data', train=False,\n",
        "                   transform=tranformaciones\n",
        "                     )\n",
        "\n",
        "## aquí puede practicar por fuera de la clase, empleando otros datasets de torchvision.datasets, como CIFAR10, FashionMNIST, etc.\n",
        "# para eso debe cargar el dataset deseado, por ejemplo:\n",
        "# FASHIONMNIST, CIFAR10, etc. (ver https://pytorch.org/vision/stable/datasets.html)\n",
        "\n",
        "# si desea trabajar con FashionMNIST, puede usar el siguiente código (descomentar):\n",
        "# train_dataset = torchvision.datasets.FashionMNIST('../data', train=True, download=True, transform=tranformaciones)\n",
        "# test_dataset = torchvision.datasets.FashionMNIST('../data', train=False, download=True, transform=tranformaciones)\n",
        "\n",
        "# o si desea trabajar con CIFAR10, puede usar el siguiente código (descomentar):\n",
        "# train_dataset = torchvision.datasets.CIFAR10('../data', train=True, download=True, transform=tranformaciones)\n",
        "# test_dataset = torchvision.datasets.CIFAR10('../data', train=False, download=True, transform=tranformaciones)\n",
        "#\n",
        "# cuando corra estos otros datasets, recuerde que las transformaciones deben ser las adecuadas para cada dataset\n",
        "# y que su arquitectura de red debe ser acorde a las dimensiones de las imágenes y al número de clases del dataset.\n",
        "\n",
        "# ahora creamos el dataloader (recordar, dataloader -> una herramienta para hacer batches de datasets)\n",
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True),\n",
        "    'test': torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oikthAE4Dteb"
      },
      "source": [
        "## 2. Ver que la base de datos esté OK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyq2UFIl-Qjy",
        "outputId": "f5f4fa73-893d-4666-e575-d8ec27aafea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "print(type(dataloader))\n",
        "print(type(dataloader['train']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dVPXQRch4xV"
      },
      "outputs": [],
      "source": [
        "# Ver imagen and label del dataloader\n",
        "train_features, train_labels = next(iter(dataloader['train']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2fs6Qdivs1H",
        "outputId": "dd976365-fad2-4970-8b88-a7ff88a7bd49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del batch de feature (input / imagen): torch.Size([64, 1, 28, 28])\n",
            "Tamaño del batch del label (clase / etiqueta): torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# verifico sus dimensiones\n",
        "print(f\"Tamaño del batch de feature (input / imagen): {train_features.size()}\")\n",
        "print(f\"Tamaño del batch del label (clase / etiqueta): {train_labels.size()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "rfK_dXQdI2C6",
        "outputId": "d1791deb-cbb8-4804-882a-40937c2fa7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tamaño de 1 imagen:  torch.Size([1, 28, 28])\n",
            "tamaño de 1 imagen DESPUES de squeeze:  torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 6\n"
          ]
        }
      ],
      "source": [
        "# tomo 1 imagen para poder visualizarla\n",
        "# y verifico sus dimensiones\n",
        "\n",
        "img = train_features[10]\n",
        "print('tamaño de 1 imagen: ', img.shape)\n",
        "# le QUITO 1 dimension (la del tamaño del batch) para poder graficar\n",
        "img = img.squeeze()\n",
        "print('tamaño de 1 imagen DESPUES de squeeze: ', img.shape)\n",
        "label = train_labels[10]\n",
        "\n",
        "# ploteo esa imagen\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFnOkkTgYTHV",
        "outputId": "5a9424a2-9255-4df7-d947-4074395662d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel [0,0]:  tensor(-0.4242)\n",
            "pixel maximo:  tensor(2.8215)\n",
            "pixel minimo:  tensor(-0.4242)\n"
          ]
        }
      ],
      "source": [
        "print('pixel [0,0]: ',img[0][0])\n",
        "print('pixel maximo: ', torch.max(img))\n",
        "print('pixel minimo: ', torch.min(img))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLDYgFptiqPd"
      },
      "source": [
        "## 3. Construyo mi CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY0TN4erDxRd"
      },
      "source": [
        "#### Bloque de convolución\n",
        "\n",
        "defino primero un \"bloque\" de una capa CNN\n",
        "construido con los bloques funcionales vistos en clase\n",
        "\n",
        "argumentos a pasar a la función:\n",
        "\n",
        "  - `c_in`:   canales (kernels) de entrada\n",
        "  - `c_out`:  canales (kernels) de salida\n",
        "  - `k`:      tamaño del kernel kxk\n",
        "  - `p`:      tamaño del padding de la convolución\n",
        "  - `s`:      stride de la convolución\n",
        "  - `pk`:     tamaño del kernel del pooling\n",
        "\n",
        "\n",
        "la función pooling se elige directamente dentro del bloque!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMxa2DAsim9t"
      },
      "outputs": [],
      "source": [
        "# bloque de convolución para emplear en mi red\n",
        "# esta función la utilizaré en la clase del a CNN\n",
        "\n",
        "def conv_block(c_in, c_out, k=3, p='same', s=1, pk=2):\n",
        "    return torch.nn.Sequential(                               # el módulo Sequential se engarga de hacer el forward de todo lo que tiene dentro.\n",
        "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
        "        torch.nn.Tanh(),                                      # activation\n",
        "        torch.nn.MaxPool2d(pk)                                # pooling\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgPfrY8VivH8"
      },
      "source": [
        "### Red convolucional (modelo)\n",
        "\n",
        "\n",
        "Ahora SI construyo mi red... usando la clase CNN de pytorch\n",
        "revisar muy bien las dimensiones a emplear en cada capa y\n",
        "tener presente la reducción de las dimensiones.\n",
        "\n",
        "En la útlima capa fully conected `fc`, hacer bien el cálculo final del\n",
        "tamaño del array que se obtiene siguiendo la formula vista en la teoria\n",
        "tanto para la capa conv como para la capa pooling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrO5gfEL3KRC"
      },
      "outputs": [],
      "source": [
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self, n_channels=1, n_outputs=10):\n",
        "    super().__init__()\n",
        "    # aquí defino la arquitectura de mi red convolucional\n",
        "    self.conv1 = conv_block(c_in = n_channels, c_out = 8, k=11, p='same', s=1, pk=2)\n",
        "    self.conv1_out = None\n",
        "    self.drop = torch.nn.Dropout2d(p=0.7, inplace=False)\n",
        "    self.conv2 = conv_block(c_in = 8, c_out = 8, k=11, p='same', s=1, pk=2)\n",
        "    self.conv2_out = None\n",
        "    self.conv3 = conv_block(c_in = 8, c_out = 8, k=11, p='same', s=1, pk=2)\n",
        "    self.conv3_out = None\n",
        "    self.fc = torch.nn.Linear(8*3*3, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
        "\n",
        "    # aquí imprimo la arquitectura de la red y el número de parámetros entrenables\n",
        "    print('----------------------------------')\n",
        "    print('Red creada')\n",
        "    print('arquitectura:')\n",
        "    print(self)\n",
        "\n",
        "    # Me fijo en el número de capas\n",
        "    i=0\n",
        "    for layer in self.children():\n",
        "        i=i+1\n",
        "    print('----------------------------------')\n",
        "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
        "\n",
        "    # Me fijo en el número de parámetros entrenables\n",
        "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "    print('----------------------------------')\n",
        "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
        "    print('----------------------------------')\n",
        "\n",
        "  # aquí defino el método forward, que es el que se ejecuta cuando llamo a la red con un input\n",
        "  def forward(self, x):\n",
        "    #print('input shape: ', x.shape)\n",
        "    self.conv1_out = self.drop(self.conv1(x))\n",
        "    self.conv2_out = self.drop(self.conv2(self.conv1_out))\n",
        "    self.conv3_out = self.conv3(self.conv2_out)\n",
        "    y = self.conv3_out\n",
        "    y = y.flatten(start_dim=1)\n",
        "    #print(y.shape)\n",
        "    y = self.fc(y)\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb6DoGaP31md",
        "outputId": "9b51b359-72d3-40f4-ddfe-bcbae05cf390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "Red creada\n",
            "arquitectura:\n",
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(11, 11), stride=(1, 1), padding=same)\n",
            "    (1): Tanh()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (drop): Dropout2d(p=0.7, inplace=False)\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(8, 8, kernel_size=(11, 11), stride=(1, 1), padding=same)\n",
            "    (1): Tanh()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(8, 8, kernel_size=(11, 11), stride=(1, 1), padding=same)\n",
            "    (1): Tanh()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=72, out_features=10, bias=True)\n",
            ")\n",
            "----------------------------------\n",
            "Número total de capas de CNN (conv+act+polling) + finales :  5\n",
            "----------------------------------\n",
            "Número total de parámetros a entrenar:  17210\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "# instancio modelo\n",
        "model = CNN()\n",
        "\n",
        "# armo config\n",
        "# OJO!! NO ESTÁ AUTOMATIZADO!\n",
        "# lo hago así para que tomen práctica sobre donde modificar en el código los\n",
        "# hyperparámetros de la red y el entrenamiento.\n",
        "model_config = {\n",
        "        \"num_layers\": 4,\n",
        "        \"kernel_size\": 11,\n",
        "        \"dropout\": 0.7,\n",
        "        \"n_channels\": [8, 8, 8],\n",
        "        \"architecture\": model.__class__.__name__\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYgRNa9M8cjI",
        "outputId": "7931c5e2-5f6b-4886-a608-1fb205cb3d3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_layers': 4,\n",
              " 'kernel_size': 11,\n",
              " 'dropout': 0.7,\n",
              " 'n_channels': [8, 8, 8],\n",
              " 'architecture': 'CNN'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4tEn-XqHVZ7"
      },
      "source": [
        "## 4. Veamos que las dimensiones sean consistentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q44d3Ftwokla",
        "outputId": "c1ef2a0d-f0aa-413b-a288-871a6ffd18a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CNN                                      [64, 10]                  --\n",
              "├─Sequential: 1-1                        [64, 8, 14, 14]           --\n",
              "│    └─Conv2d: 2-1                       [64, 8, 28, 28]           976\n",
              "│    └─Tanh: 2-2                         [64, 8, 28, 28]           --\n",
              "│    └─MaxPool2d: 2-3                    [64, 8, 14, 14]           --\n",
              "├─Dropout2d: 1-2                         [64, 8, 14, 14]           --\n",
              "├─Sequential: 1-3                        [64, 8, 7, 7]             --\n",
              "│    └─Conv2d: 2-4                       [64, 8, 14, 14]           7,752\n",
              "│    └─Tanh: 2-5                         [64, 8, 14, 14]           --\n",
              "│    └─MaxPool2d: 2-6                    [64, 8, 7, 7]             --\n",
              "├─Dropout2d: 1-4                         [64, 8, 7, 7]             --\n",
              "├─Sequential: 1-5                        [64, 8, 3, 3]             --\n",
              "│    └─Conv2d: 2-7                       [64, 8, 7, 7]             7,752\n",
              "│    └─Tanh: 2-8                         [64, 8, 7, 7]             --\n",
              "│    └─MaxPool2d: 2-9                    [64, 8, 3, 3]             --\n",
              "├─Linear: 1-6                            [64, 10]                  730\n",
              "==========================================================================================\n",
              "Total params: 17,210\n",
              "Trainable params: 17,210\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 170.57\n",
              "==========================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 4.22\n",
              "Params size (MB): 0.07\n",
              "Estimated Total Size (MB): 4.49\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# corremos el resumen de la red para ver los parámetros y tamaños intermedios\n",
        "# es necesario pasarle el tamaño de la entrada, que en este caso es (batch_size, n_channels, height, width)\n",
        "torchinfo.summary(model, input_size=( 64, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoB3GvDtGUgY"
      },
      "source": [
        "## 5. Armo las funciones necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnXzW12uM72F"
      },
      "outputs": [],
      "source": [
        "# definimo optimizer y la función de pérdida\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
        "\n",
        "# paso al config el optimizador\n",
        "model_config[\"optimizer\"] = optimizer.__class__.__name__\n",
        "\n",
        "# defino función de perdida\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Scheduler\n",
        "scheduler_type = \"step\"\n",
        "steps_per_epoch = len(dataloader['train'])\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=steps_per_epoch, T_mult=2, eta_min=1e-5)\n",
        "#scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-5, max_lr=1e-2, step_size_up=steps_per_epoch, mode=\"triangular2\")\n",
        "\n",
        "## Si queremos aplicar cambios al learning rate al final de cada epoch, usamos como ejemplo otro como este:\n",
        "#scheduler_type = \"epoch\"\n",
        "#scheduler = ExponentialLR(optimizer, gamma=0.99) # https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w-WYfZd-Yvc"
      },
      "outputs": [],
      "source": [
        "# armamos una función para entrenar el modelo con logeo de Weights & Biases (wandb)\n",
        "# a esta función hay que pasarle el modelo, el optimizador, los dataloaders de entrenamiento y evaluación,\n",
        "# la función de pérdida, el config y otros parámetros de configuración.\n",
        "\n",
        "def train_model_wandb(\n",
        "        model,\n",
        "        optimizer,\n",
        "        train_loader,\n",
        "        eval_loader,\n",
        "        loss_module,\n",
        "        config = model_config,\n",
        "        scheduler_type=\"step\",\n",
        "        patience=3,\n",
        "        patience_factor=0.01,\n",
        "        num_epochs=3,\n",
        "        scheduler = scheduler\n",
        "):\n",
        "    # Initialize Weights & Biases\n",
        "    # el nombre del proyecto es \"CEIA-Co[NUMERO_DE_COHORTE]\", y el config es el que armamos antes\n",
        "    # para que quede guardado en el log de wandb y podamos conocer los hyperparámetros empleados\n",
        "    # en ese entrenamiento\n",
        "    wandb.init(project=\"CEIA-Co22-CNN-mnist\", config=config)\n",
        "\n",
        "    ## Set device\n",
        "    model.to(device)\n",
        "\n",
        "    # Set metric for callbacks\n",
        "    best_eval = 0\n",
        "    pt_epoch = 0\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Epoch Progress\"):\n",
        "        ### Training Phase ###\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_samples = 0\n",
        "\n",
        "        for batch_idx, data in enumerate(train_loader):\n",
        "\n",
        "            X, y = data\n",
        "            # Move input data to device (if using GPU)\n",
        "            data_inputs = X.to(device)\n",
        "            data_labels = y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)  # Ensure shape consistency\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_module(preds, data_labels)\n",
        "\n",
        "            # Zero gradients, backpropagate, and update weights\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track loss for this batch\n",
        "            batch_loss = loss.item()\n",
        "            train_loss += batch_loss\n",
        "\n",
        "            # Compute accuracy (assuming classification task)\n",
        "            if preds.ndim == 2:  # Softmax case\n",
        "                preds_classes = preds.argmax(dim=1)\n",
        "            else:  # Sigmoid case (binary classification)\n",
        "                preds_classes = (preds > 0.5).long()\n",
        "\n",
        "            train_correct += (preds_classes == data_labels).sum().item()\n",
        "            train_samples += data_labels.size(0)\n",
        "\n",
        "            # Log batch-wise metrics\n",
        "            wandb.log({\n",
        "                \"batch_loss\": batch_loss,\n",
        "                \"batch_step\": epoch * len(train_loader) + batch_idx,\n",
        "                \"batch_lr\": optimizer.param_groups[0]['lr'],\n",
        "            })\n",
        "\n",
        "            # Step-level callback\n",
        "            if scheduler_type==\"step\":\n",
        "                scheduler.step()\n",
        "\n",
        "        # Compute training metrics\n",
        "        train_loss /= len(train_loader)\n",
        "        train_accuracy = train_correct / train_samples\n",
        "\n",
        "        ### Evaluation Phase ###\n",
        "        model.eval()\n",
        "        eval_loss = 0.0\n",
        "        eval_correct = 0\n",
        "        eval_samples = 0\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient tracking\n",
        "            for data in eval_loader:\n",
        "\n",
        "                X, y = data\n",
        "                data_inputs = X.to(device)\n",
        "                data_labels = y.to(device)\n",
        "\n",
        "                preds = model(data_inputs)\n",
        "                preds = preds.squeeze(dim=1)\n",
        "\n",
        "                loss = loss_module(preds, data_labels)\n",
        "                eval_loss += loss.item()\n",
        "\n",
        "                if preds.ndim == 2:\n",
        "                    preds_classes = preds.argmax(dim=1)\n",
        "                else:\n",
        "                    preds_classes = (preds > 0.5).long()\n",
        "\n",
        "                eval_correct += (preds_classes == data_labels).sum().item()\n",
        "                eval_samples += data_labels.size(0)\n",
        "\n",
        "        # Compute evaluation metrics\n",
        "        eval_loss /= len(eval_loader)\n",
        "        eval_accuracy = eval_correct / eval_samples\n",
        "\n",
        "        # Log epoch-level metrics\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_accuracy,\n",
        "            \"eval_loss\": eval_loss,\n",
        "            \"eval_accuracy\": eval_accuracy,\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_accuracy:.4f} | Eval Loss: {eval_loss:.4f} - Eval Acc: {eval_accuracy:.4f}\")\n",
        "\n",
        "        # Callbacks\n",
        "        ## Learning rate scheduler\n",
        "        if scheduler_type==\"epoch\":\n",
        "            scheduler.step()\n",
        "        ## Early stopping\n",
        "        if eval_accuracy>=best_eval*(1+patience_factor):\n",
        "            best_eval = eval_accuracy\n",
        "            pt_epoch = 0\n",
        "        else:\n",
        "            pt_epoch += 1\n",
        "            if pt_epoch>=patience:\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs} - Training interrupted due to early stopping condition.\")\n",
        "                wandb.finish()\n",
        "                break\n",
        "            else:\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs} - Current epochs without validation metric improvement {pt_epoch}. {patience-pt_epoch} remaining before stopping.\")\n",
        "\n",
        "    # Finish W&B run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cW5H0nX99DW"
      },
      "source": [
        "## 6. Entrenamiento WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "47ad8Ydj-ePT",
        "outputId": "796d9649-3884-445a-c586-7963a0cf5735"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250924_003429-b9z28907</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist/runs/b9z28907' target=\"_blank\">lyric-tree-1</a></strong> to <a href='https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist' target=\"_blank\">https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist/runs/b9z28907' target=\"_blank\">https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist/runs/b9z28907</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch Progress:   7%|▋         | 1/15 [00:19<04:29, 19.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 - Train Loss: 1.8599 - Train Acc: 0.4296 | Eval Loss: 1.2771 - Eval Acc: 0.6965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  13%|█▎        | 2/15 [00:38<04:10, 19.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15 - Train Loss: 1.2081 - Train Acc: 0.6414 | Eval Loss: 0.7159 - Eval Acc: 0.7849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  20%|██        | 3/15 [00:57<03:48, 19.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15 - Train Loss: 0.9928 - Train Acc: 0.6901 | Eval Loss: 0.6475 - Eval Acc: 0.8071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  27%|██▋       | 4/15 [01:16<03:29, 19.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15 - Train Loss: 0.8912 - Train Acc: 0.7180 | Eval Loss: 0.4860 - Eval Acc: 0.8567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  33%|███▎      | 5/15 [01:35<03:09, 18.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15 - Train Loss: 0.7846 - Train Acc: 0.7491 | Eval Loss: 0.4110 - Eval Acc: 0.8766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  40%|████      | 6/15 [01:54<02:51, 19.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15 - Train Loss: 0.7352 - Train Acc: 0.7634 | Eval Loss: 0.3790 - Eval Acc: 0.8871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  47%|████▋     | 7/15 [02:13<02:31, 18.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15 - Train Loss: 0.7172 - Train Acc: 0.7691 | Eval Loss: 0.3679 - Eval Acc: 0.8904\n",
            "Epoch 7/15 - Current epochs without validation metric improvement 1. 2 remaining before stopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  53%|█████▎    | 8/15 [02:32<02:13, 19.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15 - Train Loss: 0.6841 - Train Acc: 0.7783 | Eval Loss: 0.3102 - Eval Acc: 0.9072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  60%|██████    | 9/15 [02:51<01:53, 18.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15 - Train Loss: 0.6357 - Train Acc: 0.7927 | Eval Loss: 0.2757 - Eval Acc: 0.9151\n",
            "Epoch 9/15 - Current epochs without validation metric improvement 1. 2 remaining before stopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  67%|██████▋   | 10/15 [03:10<01:35, 19.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15 - Train Loss: 0.6025 - Train Acc: 0.8009 | Eval Loss: 0.2511 - Eval Acc: 0.9227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  73%|███████▎  | 11/15 [03:29<01:15, 18.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15 - Train Loss: 0.5892 - Train Acc: 0.8039 | Eval Loss: 0.2371 - Eval Acc: 0.9270\n",
            "Epoch 11/15 - Current epochs without validation metric improvement 1. 2 remaining before stopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  80%|████████  | 12/15 [03:48<00:57, 19.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15 - Train Loss: 0.5714 - Train Acc: 0.8090 | Eval Loss: 0.2276 - Eval Acc: 0.9295\n",
            "Epoch 12/15 - Current epochs without validation metric improvement 2. 1 remaining before stopping.\n",
            "Epoch 13/15 - Train Loss: 0.5611 - Train Acc: 0.8116 | Eval Loss: 0.2221 - Eval Acc: 0.9313\n",
            "Epoch 13/15 - Training interrupted due to early stopping condition.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>██▆▆▅▅▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>batch_lr</td><td>███▄▂▇▃▂▂█▇▆▅▅▄▂▂▂▂▂▁▁████▇▇▇▇▆▆▆▅▅▄▃▃▃▂</td></tr><tr><td>batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>eval_accuracy</td><td>▁▄▄▆▆▇▇▇█████</td></tr><tr><td>eval_loss</td><td>█▄▄▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▄█▇▄▁██▇▅▄▂▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▆▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.61357</td></tr><tr><td>batch_lr</td><td>2e-05</td></tr><tr><td>batch_step</td><td>12193</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>eval_accuracy</td><td>0.9313</td></tr><tr><td>eval_loss</td><td>0.22211</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>train_accuracy</td><td>0.81158</td></tr><tr><td>train_loss</td><td>0.56107</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lyric-tree-1</strong> at: <a href='https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist/runs/b9z28907' target=\"_blank\">https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist/runs/b9z28907</a><br> View project at: <a href='https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist' target=\"_blank\">https://wandb.ai/mmaillot/CEIA-Co21-CNN-mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250924_003429-b9z28907/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch Progress:  80%|████████  | 12/15 [04:07<01:01, 20.61s/it]\n"
          ]
        }
      ],
      "source": [
        "# corremos la función de entrenamiento con todos los argumentos correspondientes\n",
        "train_model_wandb(model, optimizer, dataloader['train'], dataloader['test'], loss_fn, scheduler_type=scheduler_type, num_epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHcr6aDtHNfc"
      },
      "source": [
        "## 7. Vemos que funcione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "k_jFvJ603PC-",
        "outputId": "2961c411-8eeb-4eb8-f902-cc083df20d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del batch de feature (input / imagen): 64\n",
            "torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAb2ElEQVR4nO3dfWyV9f3/8VcL9MhNe7pS2tNyZwGVTW6WMeg6lSF0lG4xovwhzixojAYtZlLvUjNF3WInW7zbEF1iYGSCShwQ/YNMqi27KTiqjLhpR0k3itCiJD2nFFua9vP7oz/O1wMteB3O6fucw/ORfJKe67revd5cXvbV61zX+TTNOecEAMAQS7duAABwaSKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYGK4dQNn6+vr09GjR5WZmam0tDTrdgAAHjnn1NHRocLCQqWnD36dk3ABdPToUU2cONG6DQDARWppadGECRMGXZ9wb8FlZmZatwAAiIEL/TyPWwCtW7dOl19+uS677DIVFxfrgw8++Fp1vO0GAKnhQj/P4xJAb7zxhiorK7VmzRp9+OGHmj17tsrKynT8+PF47A4AkIxcHMybN89VVFSEX/f29rrCwkJXXV19wdpgMOgkMRgMBiPJRzAYPO/P+5hfAZ0+fVoNDQ0qLS0NL0tPT1dpaanq6+vP2b67u1uhUChiAABSX8wD6IsvvlBvb6/y8/Mjlufn56u1tfWc7aurq+X3+8ODJ+AA4NJg/hRcVVWVgsFgeLS0tFi3BAAYAjH/HFBubq6GDRumtra2iOVtbW0KBALnbO/z+eTz+WLdBgAgwcX8CigjI0Nz5sxRTU1NeFlfX59qampUUlIS690BAJJUXGZCqKys1IoVK/Td735X8+bN0/PPP6/Ozk7dcccd8dgdACAJxSWAbrnlFn3++ed6/PHH1draqm9/+9vauXPnOQ8mAAAuXWnOOWfdxFeFQiH5/X7rNgAAFykYDCorK2vQ9eZPwQEALk0EEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADAx3LoBIJFMmzbNc82tt97quWbhwoWea8aPH++55oorrvBcI0nOuajqvOro6PBcE82xa2ho8FyD+OMKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgIk0N1SzDn5NoVBIfr/fug0kuX379kVVN3PmTM81w4czp+9Q6u3t9VwTDAaj2te4ceOiqkO/YDCorKysQddzBQQAMEEAAQBMxDyAnnjiCaWlpUWM6dOnx3o3AIAkF5c3r6+++mrt2rXr/3bCe+QAgLPEJRmGDx+uQCAQj28NAEgRcbkHdPDgQRUWFmrKlCm67bbbdPjw4UG37e7uVigUihgAgNQX8wAqLi7Wxo0btXPnTq1fv17Nzc267rrrBv3b79XV1fL7/eExceLEWLcEAEhAcf8cUHt7uyZPnqxnn31Wd9555znru7u71d3dHX4dCoUIIVw0PgeUuvgcUPK40OeA4v5/TnZ2tq688ko1NTUNuN7n88nn88W7DQBAgon754BOnjypQ4cOqaCgIN67AgAkkZgH0IMPPqi6ujr997//1d///nfddNNNGjZsmG699dZY7woAkMRi/hbckSNHdOutt+rEiRMaN26crr32Wu3Zs4f3UgEAEZiMFENq+fLlnmteeeUVzzWjRo3yXCNJ6ene3xQ4cuSI55q33nrLc82mTZs81wx27zVR/PSnP/Vc87vf/S4OnQyssrLSc80LL7wQh06SE5ORAgASEgEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABP8KUdEbcWKFZ5rnnrqKc81Y8aM8Vzz5ptveq6RpA8++MBzzauvvuq5JhQKea5JRVu2bPFcc++993qu+da3vuW5RpIyMjKiqsPXwxUQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEs2FDt912W1R1zz33nOcav9/vueatt97yXPPQQw95rpGkI0eORFWH6LS3t3uu+ctf/uK5JtrZsBFfXAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWSkKeaOO+7wXPP73/8+qn01Nzd7rlm4cKHnmn/961+ea3p6ejzXABhaXAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWSkKcbv93uuSU+P7veQl156yXPN/v37o9oXUtPIkSM910yZMsVzTWdnp+caSXr11VejqsPXwxUQAMAEAQQAMOE5gHbv3q0bbrhBhYWFSktL0/bt2yPWO+f0+OOPq6CgQCNHjlRpaakOHjwYq34BACnCcwB1dnZq9uzZWrdu3YDr165dqxdffFEvv/yy9u7dq9GjR6usrExdXV0X3SwAIHV4fgihvLxc5eXlA65zzun555/Xz3/+c914442SpE2bNik/P1/bt2/X8uXLL65bAEDKiOk9oObmZrW2tqq0tDS8zO/3q7i4WPX19QPWdHd3KxQKRQwAQOqLaQC1trZKkvLz8yOW5+fnh9edrbq6Wn6/PzwmTpwYy5YAAAnK/Cm4qqoqBYPB8GhpabFuCQAwBGIaQIFAQJLU1tYWsbytrS287mw+n09ZWVkRAwCQ+mIaQEVFRQoEAqqpqQkvC4VC2rt3r0pKSmK5KwBAkvP8FNzJkyfV1NQUft3c3Kz9+/crJydHkyZN0v33369f/vKXuuKKK1RUVKTHHntMhYWFWrp0aSz7BgAkOc8BtG/fPl1//fXh15WVlZKkFStWaOPGjXr44YfV2dmpu+++W+3t7br22mu1c+dOXXbZZbHrGgCQ9NKcc866ia8KhUJRTaiJfrm5uZ5rBrs/dyGNjY2ea3p6eqLaF1LTokWLPNf8+c9/9lzT0dHhuUaSsrOzo6pDv2AweN77+uZPwQEALk0EEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABOe/xwDEtsXX3wxJDXA2caPH++5ZsuWLZ5roplRvaqqynMN4o8rIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACaYjBTAOWbMmOG5ZvXq1Z5rxo4d67nm6aef9lyzfv16zzWIP66AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAyUiCFjR49Oqq6F154wXPNggULPNd8+OGHnmtefvllzzVITFwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFkpECSiGZi0WgmFZWim1i0u7vbc81TTz3lueazzz7zXIPExBUQAMAEAQQAMOE5gHbv3q0bbrhBhYWFSktL0/bt2yPW33777UpLS4sYS5YsiVW/AIAU4TmAOjs7NXv2bK1bt27QbZYsWaJjx46Fx5YtWy6qSQBA6vH8EEJ5ebnKy8vPu43P51MgEIi6KQBA6ovLPaDa2lrl5eXpqquu0j333KMTJ04Mum13d7dCoVDEAACkvpgH0JIlS7Rp0ybV1NTomWeeUV1dncrLy9Xb2zvg9tXV1fL7/eExceLEWLcEAEhAMf8c0PLly8Nfz5w5U7NmzdLUqVNVW1urRYsWnbN9VVWVKisrw69DoRAhBACXgLg/hj1lyhTl5uaqqalpwPU+n09ZWVkRAwCQ+uIeQEeOHNGJEydUUFAQ710BAJKI57fgTp48GXE109zcrP379ysnJ0c5OTl68skntWzZMgUCAR06dEgPP/ywpk2bprKyspg2DgBIbp4DaN++fbr++uvDr8/cv1mxYoXWr1+vAwcO6A9/+IPa29tVWFioxYsX6xe/+IV8Pl/sugYAJL0055yzbuKrQqGQ/H6/dRtAXA3VxKJ33HGH5xpJamho8Fzz6KOPeq7ZtWuX5xokj2AweN77+swFBwAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwEfM/yQ1cahJ5ZuvPPvvMc40kPfbYY55rmNkaXnEFBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwASTkSJqkyZN8lyTnj40v/OsWrUqqrr8/PwhqVm0aJHnmmgmFi0tLfVcI0n/+c9/oqoDvOAKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgIk055yzbuKrQqGQ/H6/dRtJa8yYMZ5rfvjDH0a1r02bNnmuGTVqVFT7QnRqamqiqvvNb37jueaf//yn55q2tjbPNdHIy8uLqu7pp5/2XLNjxw7PNW+//bbnmmQQDAaVlZU16HqugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhgMtIEtnTpUs81DzzwgOea73//+55rUlVPT4/nmlAo5Llm165dnmtuvvlmzzUjRozwXBOtjo4OzzWbN2/2XBPNxJ1lZWWeayTp008/9Vzzj3/8w3NNQ0OD55pkwGSkAICERAABAEx4CqDq6mrNnTtXmZmZysvL09KlS9XY2BixTVdXlyoqKjR27FiNGTNGy5YtG7K/+QEASB6eAqiurk4VFRXas2eP3n33XfX09Gjx4sXq7OwMb7N69Wq9/fbb2rp1q+rq6nT06NGo3rsGAKS24V423rlzZ8TrjRs3Ki8vTw0NDZo/f76CwaBeffVVbd68WQsXLpQkbdiwQd/85je1Z88efe9734td5wCApHZR94CCwaAkKScnR1L/kxw9PT0qLS0NbzN9+nRNmjRJ9fX1A36P7u5uhUKhiAEASH1RB1BfX5/uv/9+XXPNNZoxY4YkqbW1VRkZGcrOzo7YNj8/X62trQN+n+rqavn9/vCYOHFitC0BAJJI1AFUUVGhjz/+WK+//vpFNVBVVaVgMBgeLS0tF/X9AADJwdM9oDNWrVqld955R7t379aECRPCywOBgE6fPq329vaIq6C2tjYFAoEBv5fP55PP54umDQBAEvN0BeSc06pVq7Rt2za99957Kioqilg/Z84cjRgxQjU1NeFljY2NOnz4sEpKSmLTMQAgJXi6AqqoqNDmzZu1Y8cOZWZmhu/r+P1+jRw5Un6/X3feeacqKyuVk5OjrKws3XfffSopKeEJOABABE8BtH79eknSggULIpZv2LBBt99+uyTpueeeU3p6upYtW6bu7m6VlZXppZdeikmzAIDUwWSkQySa+1xnHnP3Yignn0xkX/1wtBePPPKI55ozv5jFW0VFheea6urqqPY1evToqOqGQldXl+earVu3RrWvM79YIzpMRgoASEgEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPMhj1Eovl7SLt37/ZcM2zYMM81Q+n06dOea55//nnPNc8++6znGkn6/PPPo6pLVOPGjYuqLppZoBcuXBjVvryqqqryXLN///7YN4ILYjZsAEBCIoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYILJSBNYNJMupqd7/51i7ty5nmsk6ZNPPvFc88wzz3iuaW9v91wDwB6TkQIAEhIBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATTEYKAIgLJiMFACQkAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY8BRA1dXVmjt3rjIzM5WXl6elS5eqsbExYpsFCxYoLS0tYqxcuTKmTQMAkp+nAKqrq1NFRYX27Nmjd999Vz09PVq8eLE6Ozsjtrvrrrt07Nix8Fi7dm1MmwYAJL/hXjbeuXNnxOuNGzcqLy9PDQ0Nmj9/fnj5qFGjFAgEYtMhACAlXdQ9oGAwKEnKycmJWP7aa68pNzdXM2bMUFVVlU6dOjXo9+ju7lYoFIoYAIBLgItSb2+v+/GPf+yuueaaiOWvvPKK27lzpztw4ID74x//6MaPH+9uuummQb/PmjVrnCQGg8FgpNgIBoPnzZGoA2jlypVu8uTJrqWl5bzb1dTUOEmuqalpwPVdXV0uGAyGR0tLi/lBYzAYDMbFjwsFkKd7QGesWrVK77zzjnbv3q0JEyacd9vi4mJJUlNTk6ZOnXrOep/PJ5/PF00bAIAk5imAnHO67777tG3bNtXW1qqoqOiCNfv375ckFRQURNUgACA1eQqgiooKbd68WTt27FBmZqZaW1slSX6/XyNHjtShQ4e0efNm/ehHP9LYsWN14MABrV69WvPnz9esWbPi8g8AACQpL/d9NMj7fBs2bHDOOXf48GE3f/58l5OT43w+n5s2bZp76KGHLvg+4FcFg0Hz9y0ZDAaDcfHjQj/70/5/sCSMUCgkv99v3QYA4CIFg0FlZWUNup654AAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJhIugJxz1i0AAGLgQj/PEy6AOjo6rFsAAMTAhX6ep7kEu+To6+vT0aNHlZmZqbS0tIh1oVBIEydOVEtLi7Kysow6tMdx6Mdx6Mdx6Mdx6JcIx8E5p46ODhUWFio9ffDrnOFD2NPXkp6ergkTJpx3m6ysrEv6BDuD49CP49CP49CP49DP+jj4/f4LbpNwb8EBAC4NBBAAwERSBZDP59OaNWvk8/msWzHFcejHcejHcejHceiXTMch4R5CAABcGpLqCggAkDoIIACACQIIAGCCAAIAmEiaAFq3bp0uv/xyXXbZZSouLtYHH3xg3dKQe+KJJ5SWlhYxpk+fbt1W3O3evVs33HCDCgsLlZaWpu3bt0esd87p8ccfV0FBgUaOHKnS0lIdPHjQptk4utBxuP322885P5YsWWLTbJxUV1dr7ty5yszMVF5enpYuXarGxsaIbbq6ulRRUaGxY8dqzJgxWrZsmdra2ow6jo+vcxwWLFhwzvmwcuVKo44HlhQB9MYbb6iyslJr1qzRhx9+qNmzZ6usrEzHjx+3bm3IXX311Tp27Fh4/PWvf7VuKe46Ozs1e/ZsrVu3bsD1a9eu1YsvvqiXX35Ze/fu1ejRo1VWVqaurq4h7jS+LnQcJGnJkiUR58eWLVuGsMP4q6urU0VFhfbs2aN3331XPT09Wrx4sTo7O8PbrF69Wm+//ba2bt2quro6HT16VDfffLNh17H3dY6DJN11110R58PatWuNOh6ESwLz5s1zFRUV4de9vb2usLDQVVdXG3Y19NasWeNmz55t3YYpSW7btm3h1319fS4QCLhf//rX4WXt7e3O5/O5LVu2GHQ4NM4+Ds45t2LFCnfjjTea9GPl+PHjTpKrq6tzzvX/tx8xYoTbunVreJtPPvnESXL19fVWbcbd2cfBOed+8IMfuJ/97Gd2TX0NCX8FdPr0aTU0NKi0tDS8LD09XaWlpaqvrzfszMbBgwdVWFioKVOm6LbbbtPhw4etWzLV3Nys1tbWiPPD7/eruLj4kjw/amtrlZeXp6uuukr33HOPTpw4Yd1SXAWDQUlSTk6OJKmhoUE9PT0R58P06dM1adKklD4fzj4OZ7z22mvKzc3VjBkzVFVVpVOnTlm0N6iEm4z0bF988YV6e3uVn58fsTw/P1+ffvqpUVc2iouLtXHjRl111VU6duyYnnzySV133XX6+OOPlZmZad2eidbWVkka8Pw4s+5SsWTJEt18880qKirSoUOH9Oijj6q8vFz19fUaNmyYdXsx19fXp/vvv1/XXHONZsyYIan/fMjIyFB2dnbEtql8Pgx0HCTpJz/5iSZPnqzCwkIdOHBAjzzyiBobG/WnP/3JsNtICR9A+D/l5eXhr2fNmqXi4mJNnjxZb775pu68807DzpAIli9fHv565syZmjVrlqZOnara2lotWrTIsLP4qKio0Mcff3xJ3Ac9n8GOw9133x3+eubMmSooKNCiRYt06NAhTZ06dajbHFDCvwWXm5urYcOGnfMUS1tbmwKBgFFXiSE7O1tXXnmlmpqarFsxc+Yc4Pw415QpU5Sbm5uS58eqVav0zjvv6P3334/48y2BQECnT59We3t7xPapej4MdhwGUlxcLEkJdT4kfABlZGRozpw5qqmpCS/r6+tTTU2NSkpKDDuzd/LkSR06dEgFBQXWrZgpKipSIBCIOD9CoZD27t17yZ8fR44c0YkTJ1Lq/HDOadWqVdq2bZvee+89FRUVRayfM2eORowYEXE+NDY26vDhwyl1PlzoOAxk//79kpRY54P1UxBfx+uvv+58Pp/buHGj+/e//+3uvvtul52d7VpbW61bG1IPPPCAq62tdc3Nze5vf/ubKy0tdbm5ue748ePWrcVVR0eH++ijj9xHH33kJLlnn33WffTRR+5///ufc865X/3qVy47O9vt2LHDHThwwN14442uqKjIffnll8adx9b5jkNHR4d78MEHXX19vWtubna7du1y3/nOd9wVV1zhurq6rFuPmXvuucf5/X5XW1vrjh07Fh6nTp0Kb7Ny5Uo3adIk995777l9+/a5kpISV1JSYth17F3oODQ1NbmnnnrK7du3zzU3N7sdO3a4KVOmuPnz5xt3HikpAsg5537729+6SZMmuYyMDDdv3jy3Z88e65aG3C233OIKCgpcRkaGGz9+vLvllltcU1OTdVtx9/777ztJ54wVK1Y45/ofxX7sscdcfn6+8/l8btGiRa6xsdG26Tg433E4deqUW7x4sRs3bpwbMWKEmzx5srvrrrtS7pe0gf79ktyGDRvC23z55Zfu3nvvdd/4xjfcqFGj3E033eSOHTtm13QcXOg4HD582M2fP9/l5OQ4n8/npk2b5h566CEXDAZtGz8Lf44BAGAi4e8BAQBSEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABP/D78oBO761nqJAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño imagen de entrada a red:  torch.Size([1, 1, 28, 28])\n",
            "Predición del modelo:\n",
            "tensor([[-0.1152, -1.5734,  7.9792,  2.0501, -4.7255,  0.6155, -3.4550, -0.6987,\n",
            "         -0.7724, -1.9042]], device='cuda:0')\n",
            "\n",
            "softmax de predicción:\n",
            "tensor([[3.0401e-04, 7.0729e-05, 9.9595e-01, 2.6499e-03, 3.0245e-06, 6.3129e-04,\n",
            "         1.0775e-05, 1.6961e-04, 1.5756e-04, 5.0807e-05]], device='cuda:0')\n",
            "\n",
            "El numero es un:  2\n"
          ]
        }
      ],
      "source": [
        "# corremos 1 dato, a ver como lo clasifica...\n",
        "# generamos un batch del dataloader de testeo\n",
        "test_features, test_labels = next(iter(dataloader['test']))\n",
        "# obtengo el tamaño del batch\n",
        "print(f\"Tamaño del batch de feature (input / imagen): {test_features.size(0)}\")\n",
        "\n",
        "# generamos un índice aleatorio para tomar una imagen del batch\n",
        "k = random.randint(0, test_features.size(0) - 1)\n",
        "\n",
        "# verifico las dimensiones\n",
        "samp_img = test_features[k]\n",
        "print(samp_img.shape)\n",
        "\n",
        "\n",
        "# ploteo la imagen\n",
        "plt.imshow(samp_img.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# preparo para pasarla a la red (model) asi predice.\n",
        "samp_imp = samp_img.unsqueeze(0) # agrego la batch dim\n",
        "samp_img = samp_imp.to(device) # aseguro que la imagen esté en el device correcto (GPU o CPU)\n",
        "print('Tamaño imagen de entrada a red: ', samp_img.shape)\n",
        "\n",
        "# la paso al modelo\n",
        "model.to(device)\n",
        "model.eval()\n",
        "y_hat = model(samp_img)\n",
        "print('Predición del modelo:')\n",
        "print(y_hat.detach())\n",
        "print()\n",
        "print('softmax de predicción:')\n",
        "print(torch.nn.functional.softmax(y_hat, dim=1).detach())\n",
        "print()\n",
        "print(f'El numero es un: ', torch.argmax(y_hat, axis=1).item())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "uba_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}